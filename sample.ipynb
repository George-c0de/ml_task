{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Извлечение сущностей из документов (новостных текстов)",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T17:47:42.019785Z",
     "start_time": "2024-07-17T17:45:13.599260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Установка всех зависимостей\n",
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate@ git+https://github.com/huggingface/accelerate@e1247de01e0733c5d21075cb6f39b2605f4be123 (from -r requirements.txt (line 1))\r\n",
      "  Cloning https://github.com/huggingface/accelerate (to revision e1247de01e0733c5d21075cb6f39b2605f4be123) to /private/var/folders/1q/kp4dtr7s5b50s1tnn85mv2bm0000gn/T/pip-install-3acfd_kl/accelerate_aa68812870d84ac986c629f3dbaf2197\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /private/var/folders/1q/kp4dtr7s5b50s1tnn85mv2bm0000gn/T/pip-install-3acfd_kl/accelerate_aa68812870d84ac986c629f3dbaf2197\r\n",
      "  Running command git rev-parse -q --verify 'sha^e1247de01e0733c5d21075cb6f39b2605f4be123'\r\n",
      "  Running command git fetch -q https://github.com/huggingface/accelerate e1247de01e0733c5d21075cb6f39b2605f4be123\r\n",
      "  Running command git checkout -q e1247de01e0733c5d21075cb6f39b2605f4be123\r\n",
      "  Resolved https://github.com/huggingface/accelerate to commit e1247de01e0733c5d21075cb6f39b2605f4be123\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889 (from -r requirements.txt (line 31))\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting aiohttp==3.9.5 (from -r requirements.txt (line 2))\r\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\r\n",
      "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 3))\r\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting annotated-types==0.7.0 (from -r requirements.txt (line 4))\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: anyio==4.4.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (4.4.0)\r\n",
      "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.1.4)\r\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (23.1.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (21.2.0)\r\n",
      "Requirement already satisfied: arrow==1.3.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.3.0)\r\n",
      "Requirement already satisfied: asttokens==2.4.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2.4.1)\r\n",
      "Requirement already satisfied: async-lru==2.0.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.0.4)\r\n",
      "Requirement already satisfied: attrs==23.2.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (23.2.0)\r\n",
      "Requirement already satisfied: Babel==2.15.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (2.15.0)\r\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (4.12.3)\r\n",
      "Requirement already satisfied: bleach==6.1.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (6.1.0)\r\n",
      "Collecting blis==0.7.11 (from -r requirements.txt (line 16))\r\n",
      "  Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\r\n",
      "Collecting catalogue==2.0.10 (from -r requirements.txt (line 17))\r\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: certifi==2024.7.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (2024.7.4)\r\n",
      "Requirement already satisfied: cffi==1.16.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (3.3.2)\r\n",
      "Collecting click==8.1.7 (from -r requirements.txt (line 21))\r\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting cloudpathlib==0.18.1 (from -r requirements.txt (line 22))\r\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.2.2)\r\n",
      "Collecting confection==0.1.5 (from -r requirements.txt (line 24))\r\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting cymem==2.0.8 (from -r requirements.txt (line 25))\r\n",
      "  Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\r\n",
      "Collecting datasets==2.20.0 (from -r requirements.txt (line 26))\r\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: debugpy==1.8.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (1.8.2)\r\n",
      "Requirement already satisfied: decorator==5.1.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (5.1.1)\r\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (0.7.1)\r\n",
      "Collecting dill==0.3.8 (from -r requirements.txt (line 30))\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: executing==2.0.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (2.0.1)\r\n",
      "Requirement already satisfied: fastjsonschema==2.20.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (2.20.0)\r\n",
      "Collecting filelock==3.15.4 (from -r requirements.txt (line 34))\r\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: fqdn==1.5.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (1.5.1)\r\n",
      "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 36))\r\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting fsspec==2024.5.0 (from -r requirements.txt (line 37))\r\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: h11==0.14.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (0.14.0)\r\n",
      "Requirement already satisfied: httpcore==1.0.5 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (1.0.5)\r\n",
      "Requirement already satisfied: httpx==0.27.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (0.27.0)\r\n",
      "Collecting huggingface-hub==0.23.4 (from -r requirements.txt (line 41))\r\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: idna==3.7 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (3.7)\r\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (6.29.5)\r\n",
      "Requirement already satisfied: ipython==8.26.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (8.26.0)\r\n",
      "Requirement already satisfied: ipywidgets==8.1.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (8.1.3)\r\n",
      "Requirement already satisfied: isoduration==20.11.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (20.11.0)\r\n",
      "Requirement already satisfied: jedi==0.19.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (0.19.1)\r\n",
      "Requirement already satisfied: Jinja2==3.1.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (3.1.4)\r\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 49))\r\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Requirement already satisfied: json5==0.9.25 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 50)) (0.9.25)\r\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 51)) (3.0.0)\r\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 52)) (4.23.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications==2023.12.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (2023.12.1)\r\n",
      "Requirement already satisfied: jupyter==1.0.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 54)) (1.0.0)\r\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 55)) (6.6.3)\r\n",
      "Requirement already satisfied: jupyter-events==0.10.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 56)) (0.10.0)\r\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 57)) (2.2.5)\r\n",
      "Requirement already satisfied: jupyter_client==8.6.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 58)) (8.6.2)\r\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 59)) (5.7.2)\r\n",
      "Requirement already satisfied: jupyter_server==2.14.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 60)) (2.14.2)\r\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 61)) (0.5.3)\r\n",
      "Requirement already satisfied: jupyterlab==4.2.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 62)) (4.2.3)\r\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 63)) (0.3.0)\r\n",
      "Collecting jupyterlab_server==2.27.2 (from -r requirements.txt (line 64))\r\n",
      "  Downloading jupyterlab_server-2.27.2-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.11 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 65)) (3.0.11)\r\n",
      "Collecting langcodes==3.4.0 (from -r requirements.txt (line 66))\r\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\r\n",
      "Collecting language_data==1.2.0 (from -r requirements.txt (line 67))\r\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting marisa-trie==1.2.0 (from -r requirements.txt (line 68))\r\n",
      "  Downloading marisa_trie-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.7 kB)\r\n",
      "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 69))\r\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 70)) (2.1.5)\r\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 71)) (0.1.7)\r\n",
      "Collecting mdurl==0.1.2 (from -r requirements.txt (line 72))\r\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: mistune==3.0.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 73)) (3.0.2)\r\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 74))\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting multidict==6.0.5 (from -r requirements.txt (line 75))\r\n",
      "  Downloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\r\n",
      "Collecting multiprocess==0.70.16 (from -r requirements.txt (line 76))\r\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting murmurhash==1.0.10 (from -r requirements.txt (line 77))\r\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: nbclient==0.10.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 78)) (0.10.0)\r\n",
      "Requirement already satisfied: nbconvert==7.16.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 79)) (7.16.4)\r\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 80)) (5.10.4)\r\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 81)) (1.6.0)\r\n",
      "Collecting networkx==3.3 (from -r requirements.txt (line 82))\r\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: notebook==7.2.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 83)) (7.2.1)\r\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 84)) (0.2.4)\r\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 85))\r\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m114.8/114.8 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: overrides==7.7.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 86)) (7.7.0)\r\n",
      "Requirement already satisfied: packaging==24.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 87)) (24.1)\r\n",
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 88))\r\n",
      "  Downloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 89)) (1.5.1)\r\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 90)) (0.8.4)\r\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 91)) (4.9.0)\r\n",
      "Collecting pillow==10.4.0 (from -r requirements.txt (line 92))\r\n",
      "  Downloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: platformdirs==4.2.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 93)) (4.2.2)\r\n",
      "Collecting preshed==3.0.9 (from -r requirements.txt (line 94))\r\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: prometheus_client==0.20.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 95)) (0.20.0)\r\n",
      "Requirement already satisfied: prompt_toolkit==3.0.47 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 96)) (3.0.47)\r\n",
      "Requirement already satisfied: psutil==6.0.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 97)) (6.0.0)\r\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 98)) (0.7.0)\r\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 99)) (0.2.2)\r\n",
      "Collecting pyarrow==16.1.0 (from -r requirements.txt (line 100))\r\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\r\n",
      "Collecting pyarrow-hotfix==0.6 (from -r requirements.txt (line 101))\r\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: pycparser==2.22 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 102)) (2.22)\r\n",
      "Collecting pydantic==2.8.2 (from -r requirements.txt (line 103))\r\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m125.2/125.2 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting pydantic_core==2.20.1 (from -r requirements.txt (line 104))\r\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: Pygments==2.18.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 105)) (2.18.0)\r\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 106)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: python-json-logger==2.0.7 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 107)) (2.0.7)\r\n",
      "Collecting pytz==2024.1 (from -r requirements.txt (line 108))\r\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: PyYAML==6.0.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 109)) (6.0.1)\r\n",
      "Requirement already satisfied: pyzmq==26.0.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 110)) (26.0.3)\r\n",
      "Requirement already satisfied: qtconsole==5.5.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 111)) (5.5.2)\r\n",
      "Requirement already satisfied: QtPy==2.4.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 112)) (2.4.1)\r\n",
      "Requirement already satisfied: referencing==0.35.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 113)) (0.35.1)\r\n",
      "Collecting regex==2024.5.15 (from -r requirements.txt (line 114))\r\n",
      "  Downloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 115)) (2.32.3)\r\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 116)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 117)) (0.1.1)\r\n",
      "Collecting rich==13.7.1 (from -r requirements.txt (line 118))\r\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: rpds-py==0.19.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 119)) (0.19.0)\r\n",
      "Collecting safetensors==0.4.3 (from -r requirements.txt (line 120))\r\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Collecting scikit-learn==1.5.1 (from -r requirements.txt (line 121))\r\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting scipy==1.14.0 (from -r requirements.txt (line 122))\r\n",
      "  Downloading scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.8/60.8 kB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: Send2Trash==1.8.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 123)) (1.8.3)\r\n",
      "Collecting shellingham==1.5.4 (from -r requirements.txt (line 124))\r\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: six==1.16.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 125)) (1.16.0)\r\n",
      "Collecting smart-open==7.0.4 (from -r requirements.txt (line 126))\r\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\r\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 127)) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve==2.5 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 128)) (2.5)\r\n",
      "Collecting spacy==3.7.5 (from -r requirements.txt (line 129))\r\n",
      "  Downloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\r\n",
      "Collecting spacy-legacy==3.0.12 (from -r requirements.txt (line 130))\r\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting spacy-loggers==1.0.5 (from -r requirements.txt (line 131))\r\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\r\n",
      "Collecting srsly==2.4.8 (from -r requirements.txt (line 132))\r\n",
      "  Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 133)) (0.6.3)\r\n",
      "Collecting sympy==1.13.0 (from -r requirements.txt (line 134))\r\n",
      "  Downloading sympy-1.13.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: terminado==0.18.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 135)) (0.18.1)\r\n",
      "Collecting thinc==8.2.5 (from -r requirements.txt (line 136))\r\n",
      "  Downloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\r\n",
      "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 137))\r\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: tinycss2==1.3.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 138)) (1.3.0)\r\n",
      "Collecting tokenizers==0.19.1 (from -r requirements.txt (line 139))\r\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting torch==2.3.1 (from -r requirements.txt (line 140))\r\n",
      "  Using cached torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\r\n",
      "Requirement already satisfied: tornado==6.4.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 141)) (6.4.1)\r\n",
      "Collecting tqdm==4.66.4 (from -r requirements.txt (line 142))\r\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 143)) (5.14.3)\r\n",
      "Collecting transformers==4.42.4 (from -r requirements.txt (line 144))\r\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting typer==0.12.3 (from -r requirements.txt (line 145))\r\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20240316 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 146)) (2.9.0.20240316)\r\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 147)) (4.12.2)\r\n",
      "Collecting tzdata==2024.1 (from -r requirements.txt (line 148))\r\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: uri-template==1.3.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 149)) (1.3.0)\r\n",
      "Requirement already satisfied: urllib3==2.2.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 150)) (2.2.2)\r\n",
      "Collecting wasabi==1.1.3 (from -r requirements.txt (line 151))\r\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\r\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 152)) (0.2.13)\r\n",
      "Collecting weasel==0.4.1 (from -r requirements.txt (line 153))\r\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Requirement already satisfied: webcolors==24.6.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 154)) (24.6.0)\r\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 155)) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client==1.8.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 156)) (1.8.0)\r\n",
      "Requirement already satisfied: widgetsnbextension==4.0.11 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 157)) (4.0.11)\r\n",
      "Collecting wrapt==1.16.0 (from -r requirements.txt (line 158))\r\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Collecting xxhash==3.4.1 (from -r requirements.txt (line 159))\r\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting yarl==1.9.4 (from -r requirements.txt (line 160))\r\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: setuptools>=40.1.0 in ./.venv/lib/python3.11/site-packages (from jupyterlab==4.2.3->-r requirements.txt (line 62)) (70.1.1)\r\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m390.2/390.2 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\r\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m97.9/97.9 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.3/47.3 kB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\r\n",
      "Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m41.2/41.2 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m547.8/547.8 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\r\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.4/53.4 kB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m316.1/316.1 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m402.6/402.6 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.8/301.8 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading jupyterlab_server-2.27.2-py3-none-any.whl (59 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.4/59.4 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading langcodes-3.4.0-py3-none-any.whl (182 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m182.0/182.0 kB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.4/5.4 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading marisa_trie-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m174.6/174.6 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m87.5/87.5 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.5/143.5 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\r\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.0/14.0 MB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.3/11.3 MB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.8/128.8 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl (26.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.0/26.0 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m423.9/423.9 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m505.5/505.5 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl (278 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m278.3/278.3 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m240.7/240.7 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl (410 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.3/410.3 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.0/11.0 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.1/23.1 MB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\r\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.2/61.2 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\r\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\r\n",
      "Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl (488 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m488.4/488.4 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sympy-1.13.0-py3-none-any.whl (6.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.2/6.2 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl (773 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m773.9/773.9 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached torch-2.3.1-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\r\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 kB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.3/9.3 MB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.2/47.2 kB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m345.4/345.4 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\r\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.3/50.3 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\r\n",
      "Downloading xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.2/81.2 kB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: accelerate\r\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for accelerate: filename=accelerate-0.33.0.dev0-py3-none-any.whl size=315133 sha256=8c7f1589adfe16641e75a3fda49cad36266aa36771a3b0719f0e7cc58d4a8242\r\n",
      "  Stored in directory: /Users/george/Library/Caches/pip/wheels/3e/8a/fe/bfbf7bb966a5c75668e03e6b6ee764ed600c6af82bbc77a9e0\r\n",
      "Successfully built accelerate\r\n",
      "Installing collected packages: pytz, mpmath, cymem, xxhash, wrapt, wasabi, tzdata, tqdm, threadpoolctl, sympy, spacy-loggers, spacy-legacy, shellingham, safetensors, regex, pydantic_core, pyarrow-hotfix, pillow, numpy, networkx, murmurhash, multidict, mdurl, marisa-trie, joblib, fsspec, frozenlist, filelock, dill, cloudpathlib, click, catalogue, annotated-types, yarl, torch, srsly, smart-open, scipy, pydantic, pyarrow, preshed, pandas, multiprocess, markdown-it-py, language_data, huggingface-hub, blis, aiosignal, tokenizers, scikit-learn, rich, langcodes, confection, aiohttp, accelerate, typer, transformers, thinc, weasel, datasets, spacy, en-core-web-sm, jupyterlab_server\r\n",
      "  Attempting uninstall: jupyterlab_server\r\n",
      "    Found existing installation: jupyterlab_server 2.27.3\r\n",
      "    Uninstalling jupyterlab_server-2.27.3:\r\n",
      "      Successfully uninstalled jupyterlab_server-2.27.3\r\n",
      "Successfully installed accelerate-0.33.0.dev0 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 datasets-2.20.0 dill-0.3.8 en-core-web-sm-3.7.1 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.5.0 huggingface-hub-0.23.4 joblib-1.4.2 jupyterlab_server-2.27.2 langcodes-3.4.0 language_data-1.2.0 marisa-trie-1.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.16 murmurhash-1.0.10 networkx-3.3 numpy-1.26.4 pandas-2.2.2 pillow-10.4.0 preshed-3.0.9 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydantic-2.8.2 pydantic_core-2.20.1 pytz-2024.1 regex-2024.5.15 rich-13.7.1 safetensors-0.4.3 scikit-learn-1.5.1 scipy-1.14.0 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 sympy-1.13.0 thinc-8.2.5 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 tqdm-4.66.4 transformers-4.42.4 typer-0.12.3 tzdata-2024.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.16.0 xxhash-3.4.1 yarl-1.9.4\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in ./.venv/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (70.1.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./.venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:23:34.172721Z",
     "start_time": "2024-07-14T20:23:28.607893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Создание примерного файла news_texts.csv\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Apple is looking at buying U.K. startup for $1 billion\",\n",
    "        \"San Francisco considers banning sidewalk delivery robots\",\n",
    "        \"London is a very big city in the United Kingdom\",\n",
    "        \"The quick brown fox jumps over the lazy dog\",\n",
    "        \"Artificial Intelligence is transforming the tech industry\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('news_texts.csv', index=False)"
   ],
   "id": "c711dba5f764921d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:23:34.513558Z",
     "start_time": "2024-07-14T20:23:34.173628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Пример загрузки данных\n",
    "data = pd.read_csv('news_texts.csv')\n",
    "texts = data['text'].tolist()\n",
    "\n",
    "# Загрузка модели spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "# Функция для извлечения сущностей\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "\n",
    "# Применение функции ко всем текстам\n",
    "data['entities'] = data['text'].apply(extract_entities)\n",
    "\n",
    "# Сохранение результатов\n",
    "data.to_csv('entities_extracted.csv', index=False)\n"
   ],
   "id": "57b0f1b74bc847e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Теория для VLM\n",
    "Визуальные языковые модели (VLM) представляют собой специализированные системы искусственного интеллекта, которые учатся понимать визуальные данные, такие как изображения и графики, в контексте текстовых запросов или описаний. Эти модели основаны на глубоком обучении и обычно используют архитектуры, подобные тем, что успешно применяются для обработки текста, например, Transformer \n",
    "\n",
    "Процесс обучения VLM начинается с предварительного обучения на больших наборах данных, где модель учится распознавать паттерны и взаимосвязи между визуальными и текстовыми данными. Это включает анализ изображений и соответствующих текстовых описаний или ответов на вопросы о визуальных данных"
   ],
   "id": "beb42ef8c14aae6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Выбор модели VLM\n",
    "Для задачи Chart Question Answering рассмотрим следующие модели: \n",
    "* LXMERT \n",
    "* VisualBERT \n",
    "* ViLT (Vision-and-Language Transformer)\n",
    "\n",
    "ViLT отличается простотой в дообучении и инференсе, а также возможностью квантизации\n",
    "Архитектура VLM: \n",
    "1. Визуальная часть: CNN, ResNet, EfficientNet, ViT. \n",
    "2. Текстовая часть: Трансформеры (BERT, GPT). \n",
    "3. Мультимодальная часть: Интеграция визуальных и текстовых данных с помощью attention mechanisms (LXMERT, VisualBERT, ViLBERT)\n",
    "\n",
    "Обучение VLM: \n",
    "Предварительное обучение: Обучение на больших объемах данных. Тонкая настройка: Дообучение на специфических датасетах. \n",
    "Дополнительные методы: Transfer learning, квантизация, оптимизация\n",
    "\n",
    "Выбор датасета \n",
    "Для задачи Chart Question Answering: ChartMimic: Специально созданный для анализа графиков и диаграмм ChartMimic на Huggingface ChartLlama-Dataset: Для задач вопрос-ответ по графикам ChartLlama-Dataset на Huggingface"
   ],
   "id": "efdec86c20c0819f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:35:45.522916Z",
     "start_time": "2024-07-17T18:35:39.265138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets.formatting.formatting import LazyBatch\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Determine device\n",
    "# Raise RuntimeError: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load model and processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Load dataset, data load_dataset not working and i use get request\n",
    "response = requests.get(\n",
    "    url=\"https://datasets-server.huggingface.co/first-rows?dataset=listen2you002%2FChartLlama-Dataset&config=default&split=train\").json()\n",
    "\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(row['row'] for row in response['rows']))\n",
    "\n",
    "\n",
    "# Function to load image using PIL\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image and returns it as a numpy array.\n",
    "    Args:\n",
    "        image_path: \n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    return Image.open(image_path)\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "def preprocess(examples: LazyBatch):\n",
    "    \"\"\"\n",
    "    Preprocessing step of the dataset.\n",
    "    Args:\n",
    "        examples: \n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    images = [load_image(image) for image in examples['image']]\n",
    "    text = [\",\".join(asc[\"value\"] for asc in row) for row in examples['conversations']]\n",
    "    inputs = processor(text=text, images=images, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Split into train and test datasets\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    output_dir='./clip-chartmimic'\n",
    ")\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n"
   ],
   "id": "a2375eba85e4f9c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b412db9311f48408e6a3507666cc8c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'conversations', 'id', 'model']\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 68\u001B[0m\n\u001B[1;32m     60\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     61\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     62\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m     63\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtrain_dataset,\n\u001B[1;32m     64\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mtest_dataset,\n\u001B[1;32m     65\u001B[0m )\n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 68\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[1;32m     71\u001B[0m trainer\u001B[38;5;241m.\u001B[39mevaluate()\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:1932\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1930\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1931\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1932\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1933\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1934\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1935\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1936\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1937\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:2268\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   2267\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 2268\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2270\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2271\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   2272\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m   2273\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   2274\u001B[0m ):\n\u001B[1;32m   2275\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   2276\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:3307\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   3304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   3306\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 3307\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3309\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m inputs\n\u001B[1;32m   3311\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:3338\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   3336\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3337\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 3338\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3339\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   3340\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   3341\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:1110\u001B[0m, in \u001B[0;36mCLIPModel.forward\u001B[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1105\u001B[0m output_hidden_states \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1106\u001B[0m     output_hidden_states \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39moutput_hidden_states\n\u001B[1;32m   1107\u001B[0m )\n\u001B[1;32m   1108\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1110\u001B[0m vision_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvision_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1117\u001B[0m text_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_model(\n\u001B[1;32m   1118\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1119\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1123\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1124\u001B[0m )\n\u001B[1;32m   1126\u001B[0m image_embeds \u001B[38;5;241m=\u001B[39m vision_outputs[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:849\u001B[0m, in \u001B[0;36mCLIPVisionTransformer.forward\u001B[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pixel_values \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    847\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have to specify pixel_values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 849\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_layrnorm(hidden_states)\n\u001B[1;32m    852\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m    853\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39mhidden_states,\n\u001B[1;32m    854\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    855\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    856\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    857\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:184\u001B[0m, in \u001B[0;36mCLIPVisionEmbeddings.forward\u001B[0;34m(self, pixel_values)\u001B[0m\n\u001B[1;32m    182\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m pixel_values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    183\u001B[0m target_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_embedding\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m--> 184\u001B[0m patch_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# shape = [*, width, grid, grid]\u001B[39;00m\n\u001B[1;32m    185\u001B[0m patch_embeds \u001B[38;5;241m=\u001B[39m patch_embeds\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    187\u001B[0m class_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_embedding\u001B[38;5;241m.\u001B[39mexpand(batch_size, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml_task/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выбор метрики: Accuracy (точность)",
   "id": "f931f84d3440b0cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T20:29:40.113291Z",
     "start_time": "2024-07-14T20:29:39.688845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Оценка точности модели до и после дообучения\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Точность модели после дообучения: {eval_results['eval_accuracy']}\")\n"
   ],
   "id": "2a9491f0e3f00a55",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Оценка точности модели до и после дообучения\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m eval_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mТочность модели после дообучения: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00meval_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:3641\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3638\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m   3640\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[0;32m-> 3641\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3642\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3643\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3644\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[1;32m   3645\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[1;32m   3646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   3647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3649\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3651\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[1;32m   3652\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:3826\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[1;32m   3823\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m observed_batch_size\n\u001B[1;32m   3825\u001B[0m \u001B[38;5;66;03m# Prediction step\u001B[39;00m\n\u001B[0;32m-> 3826\u001B[0m losses, logits, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprediction_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3827\u001B[0m main_input_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain_input_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3828\u001B[0m inputs_decode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_input(inputs[main_input_name]) \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39minclude_inputs_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/transformers/trainer.py:4050\u001B[0m, in \u001B[0;36mTrainer.prediction_step\u001B[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001B[0m\n\u001B[1;32m   4048\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4049\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 4050\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4051\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m   4052\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ignore_keys)\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:1110\u001B[0m, in \u001B[0;36mCLIPModel.forward\u001B[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1105\u001B[0m output_hidden_states \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1106\u001B[0m     output_hidden_states \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39moutput_hidden_states\n\u001B[1;32m   1107\u001B[0m )\n\u001B[1;32m   1108\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1110\u001B[0m vision_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvision_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpixel_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1117\u001B[0m text_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_model(\n\u001B[1;32m   1118\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1119\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1123\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1124\u001B[0m )\n\u001B[1;32m   1126\u001B[0m image_embeds \u001B[38;5;241m=\u001B[39m vision_outputs[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:849\u001B[0m, in \u001B[0;36mCLIPVisionTransformer.forward\u001B[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pixel_values \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    847\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have to specify pixel_values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 849\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    850\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_layrnorm(hidden_states)\n\u001B[1;32m    852\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m    853\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39mhidden_states,\n\u001B[1;32m    854\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    855\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    856\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    857\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:184\u001B[0m, in \u001B[0;36mCLIPVisionEmbeddings.forward\u001B[0;34m(self, pixel_values)\u001B[0m\n\u001B[1;32m    182\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m pixel_values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    183\u001B[0m target_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_embedding\u001B[38;5;241m.\u001B[39mweight\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m--> 184\u001B[0m patch_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpixel_values\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# shape = [*, width, grid, grid]\u001B[39;00m\n\u001B[1;32m    185\u001B[0m patch_embeds \u001B[38;5;241m=\u001B[39m patch_embeds\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    187\u001B[0m class_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_embedding\u001B[38;5;241m.\u001B[39mexpand(batch_size, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/test_task/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "48fa553e3ea98101",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
